{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":240,"sourceType":"datasetVersion","datasetId":110},{"sourceId":8830477,"sourceType":"datasetVersion","datasetId":5313174}],"dockerImageVersionId":30120,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Anomaly Detection in Time Series Data**\n\nThis will be a **short notebook exploring Anomaly Detection**. I will, initially, use just one algorithm (**Isolation Forest**), but with the view to expand this notebook over time.\n\nThe Isolation Forest ‘isolates’ observations by randomly selecting a feature and then randomly selecting a split value between the maximum and minimum values of the selected feature.\n\nSince recursive partitioning can be represented by a tree structure, the number of splittings required to isolate a sample is equivalent to the path length from the root node to the terminating node.\n\nThis path length, averaged over a forest of such random trees, is a measure of normality and our decision function.\n\nRandom partitioning produces noticeably shorter paths for anomalies. Hence, when a forest of random trees collectively produce shorter path lengths for particular samples, they are highly likely to be anomalies.\n\n## **Different Approaches to Time Series Anomaly Detection**\n\nCheck out this notebook I put together to showcase the **STUMPY** Matrix Profiling library and how it can be used for anomaly detection:\n\nhttps://www.kaggle.com/code/joshuaswords/anomaly-detection-with-stumpy-matrix-profiling","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-07-01T17:52:39.872432Z","iopub.execute_input":"2024-07-01T17:52:39.872758Z","iopub.status.idle":"2024-07-01T17:52:39.883228Z","shell.execute_reply.started":"2024-07-01T17:52:39.872687Z","shell.execute_reply":"2024-07-01T17:52:39.882103Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing\n\nExplanation\nDirectory Path: The data_dir variable should be set to the path of the main directory containing your annotated data directories.\n\nReading Files: We loop through each activity directory within the main directory and then loop through each file in these directories. For each file, we extract metadata (activity type, sensor type, participant ID, and trial number) from the filename.\n\nReading Data: Each CSV file is read into a DataFrame using pd.read_csv. No header is present in the data files (header=None).\n\nCombining Data: Metadata columns are added to each DataFrame, and these DataFrames are appended to a list. All DataFrames in the list are then concatenated into a single DataFrame using pd.concat.\n\nOptional Saving: The combined DataFrame is saved to a new CSV file named combined_mobiact_dataset.csv.","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport glob\nimport random\n\ndef load_and_combine_data(data_folder, sample_percentage=100):\n    # Recursively search for all activity folders\n    activity_folders = glob.glob(os.path.join(data_folder, '*'))\n    \n    # Create an empty list to store the data\n    all_data = []\n\n    # Iterate through each activity folder\n    for activity_folder in activity_folders:\n        print(f\"Processing activity folder: {activity_folder}\")\n        \n        # Search for all CSV files within the current activity folder\n        data_files = glob.glob(os.path.join(activity_folder, '*.csv'))\n        \n        # Shuffle the list of data files to ensure random sampling\n        random.shuffle(data_files)\n        \n        # Calculate the number of files to load based on the sample percentage\n        num_files_to_load = int(len(data_files) * sample_percentage / 100)\n        \n        # Iterate through each CSV file in the current activity folder\n        for i, file in enumerate(data_files):\n            if i < num_files_to_load:\n                file_path = os.path.abspath(file)\n                data = pd.read_csv(file_path)\n                \n                # Extract metadata from the filename\n                parts = os.path.basename(file).split('_')\n                activity_type = parts[0]\n                sensor_type = parts[1]\n                participant_id = parts[2]\n                trial_no = parts[3].split('.')[0]\n                \n                # Add metadata columns to the DataFrame\n                data['Activity Type'] = activity_type\n                data['Sensor Type'] = sensor_type\n                data['Participant ID'] = participant_id\n                data['Trial No'] = trial_no\n                \n                all_data.append(data)\n                #### print(f\"Loaded {i+1}/{num_files_to_load} files for this activity.\")\n    \n    # Concatenate all the loaded data into a single DataFrame\n    combined_data = pd.concat(all_data, ignore_index=True)\n    \n    return combined_data\n\n# Define the path to the annotated data folder\ndata_folder = '/kaggle/input/mobiact-dataset-v2/MobiAct_Dataset_v2.0/Annotated Data'\nsample_percentage = 8  # Load only 30% of the dataset\n\n# Load and combine data from all activity folders with sampling\ncombined_data = load_and_combine_data(data_folder, sample_percentage)\n\n# Export combined data to a CSV file\noutput_file = 'combined_mobiact_dataset.csv'\ncombined_data.to_csv(output_file, index=False)\nprint(f\"Combined data exported to {output_file}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-01T17:52:39.884526Z","iopub.execute_input":"2024-07-01T17:52:39.884765Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Processing activity folder: /kaggle/input/mobiact-dataset-v2/MobiAct_Dataset_v2.0/Annotated Data/FOL\nProcessing activity folder: /kaggle/input/mobiact-dataset-v2/MobiAct_Dataset_v2.0/Annotated Data/CSO\nProcessing activity folder: /kaggle/input/mobiact-dataset-v2/MobiAct_Dataset_v2.0/Annotated Data/STU\nProcessing activity folder: /kaggle/input/mobiact-dataset-v2/MobiAct_Dataset_v2.0/Annotated Data/SDL\nProcessing activity folder: /kaggle/input/mobiact-dataset-v2/MobiAct_Dataset_v2.0/Annotated Data/SLH\nProcessing activity folder: /kaggle/input/mobiact-dataset-v2/MobiAct_Dataset_v2.0/Annotated Data/SCH\nProcessing activity folder: /kaggle/input/mobiact-dataset-v2/MobiAct_Dataset_v2.0/Annotated Data/STN\nProcessing activity folder: /kaggle/input/mobiact-dataset-v2/MobiAct_Dataset_v2.0/Annotated Data/SBE\nProcessing activity folder: /kaggle/input/mobiact-dataset-v2/MobiAct_Dataset_v2.0/Annotated Data/WAL\nProcessing activity folder: /kaggle/input/mobiact-dataset-v2/MobiAct_Dataset_v2.0/Annotated Data/CSI\nProcessing activity folder: /kaggle/input/mobiact-dataset-v2/MobiAct_Dataset_v2.0/Annotated Data/SIT\nProcessing activity folder: /kaggle/input/mobiact-dataset-v2/MobiAct_Dataset_v2.0/Annotated Data/SBW\nProcessing activity folder: /kaggle/input/mobiact-dataset-v2/MobiAct_Dataset_v2.0/Annotated Data/FKL\nProcessing activity folder: /kaggle/input/mobiact-dataset-v2/MobiAct_Dataset_v2.0/Annotated Data/JUM\nProcessing activity folder: /kaggle/input/mobiact-dataset-v2/MobiAct_Dataset_v2.0/Annotated Data/SRH\nProcessing activity folder: /kaggle/input/mobiact-dataset-v2/MobiAct_Dataset_v2.0/Annotated Data/BSC\nProcessing activity folder: /kaggle/input/mobiact-dataset-v2/MobiAct_Dataset_v2.0/Annotated Data/STD\nProcessing activity folder: /kaggle/input/mobiact-dataset-v2/MobiAct_Dataset_v2.0/Annotated Data/JOG\nProcessing activity folder: /kaggle/input/mobiact-dataset-v2/MobiAct_Dataset_v2.0/Annotated Data/SLW\nProcessing activity folder: /kaggle/input/mobiact-dataset-v2/MobiAct_Dataset_v2.0/Annotated Data/CHU\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 1. Load the Combined Dataset\nWe'll load the dataset using pandas.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Load the combined dataset\nfile_path = '/kaggle/working/combined_mobiact_dataset.csv'\ndf = pd.read_csv(file_path)\n\n# Display the first few rows of the dataframe\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming 'Type Activity' is the column containing fall types\n\n# Create a list of fall types\nfall_types = ['FOL', 'FKL', 'BSC', 'SDL']\n\n# Create a new column 'Fall' to indicate true/false for falls\ndf['Fall'] = df['Activity Type'].isin(fall_types)\n\n# Convert 'Fall' column to integer (0 for false, 1 for true)\ndf['Fall'] = df['Fall'].astype(int)\n\n# Print the updated DataFrame\nprint(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Check the Structure and Summary Statistics\nWe'll examine the structure and summary statistics to understand the dataset better.","metadata":{}},{"cell_type":"code","source":"# Display basic information about the dataset\ndf.info()\n\n# Display summary statistics\ndf.describe()\n\n# Display the unique activities in the dataset\ndf['Activity Type'].unique()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Visualize the Distribution of Activities\nWe'll create a bar plot to visualize the distribution of different activities in the dataset.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Count the occurrences of each activity type\nactivity_counts = df['Activity Type'].value_counts()\n\n# Create a bar plot of the activity distribution\nplt.figure(figsize=(12, 6))\nsns.barplot(x=activity_counts.index, y=activity_counts.values, palette='viridis')\nplt.title('Distribution of Activities')\nplt.xlabel('Activity Type')\nplt.ylabel('Count')\nplt.xticks(rotation=45)\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Evaluate the Quality of the Dataset\nWe'll check for missing values and inconsistencies to assess the dataset's quality.","metadata":{}},{"cell_type":"code","source":"# Check for missing values\nmissing_values = df.isnull().sum()\n\n# Display columns with missing values\nmissing_values[missing_values > 0]\n\n# Check for duplicates\nduplicate_rows = df.duplicated().sum()\n\n# Display the number of duplicate rows\nduplicate_rows\n\n# Check the balance of activities\nactivity_balance = df['Activity Type'].value_counts(normalize=True) * 100\n\n# Display the balance of activities\nactivity_balance","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Visualize Sensor Data for Each Activity\nWe'll plot sensor data for a few activities to get an idea of the data quality and patterns.","metadata":{}},{"cell_type":"code","source":"# Sample a few activities to plot\nsample_activities = df['Activity Type'].unique()[:3]\n\n# Plot sensor data for each sampled activity\nfig, axes = plt.subplots(len(sample_activities), 1, figsize=(12, 8), sharex=True)\n\nfor i, activity in enumerate(sample_activities):\n    activity_data = df[df['Activity Type'] == activity].iloc[:, :-4]  # Exclude metadata columns\n    activity_data.plot(ax=axes[i], title=activity, legend=False)\n    axes[i].set_ylabel('Sensor Value')\n\nplt.xlabel('Time')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It will be good to do some **Feauture Engineering** later to extract as much information as we can from these existing features.","metadata":{}},{"cell_type":"markdown","source":"**Housekeeping**\n\nChecking for blank values, checking Data Types etc.","metadata":{}},{"cell_type":"code","source":"def overview(df: pd.DataFrame, timestamp_col: str = None) -> None:\n    print('Null Count:\\n', df.isnull().sum(),'\\n')\n    print('Data Types:\\n', df.dtypes)\n    \n    if timestamp_col is not None:\n        print('\\nDate Range:\\n\\nStart:\\t',df[timestamp_col].min())\n        print('End:\\t',df[timestamp_col].max())\n        print('Days:\\t',(df[timestamp_col].max() - df[timestamp_col].min()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"overview(df, timestamp_col='timestamp')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test plot","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Assuming you have a DataFrame named 'df' with fall data\n\n# Extract fall data based on fall types\nfall_types = ['FOL', 'FKL', 'BSC', 'SDL']\nfall_data = df[df['Activity Type'].isin(fall_types)]\n\nprint(fall_data.head())\nif True == False :\n    # Create a pair plot for each fall type\n    for fall_type in fall_types:\n        fall_type_data = fall_data[fall_data['Activity Type'] == fall_type]\n\n        # Select relevant features for plotting\n        features = ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z']\n\n        # Create a pair plot\n        g = sns.PairGrid(fall_type_data[features], diag_sharey=False)\n        g.map_upper(sns.scatterplot, alpha=0.5)\n        g.map_lower(sns.kdeplot, fill=True)\n        g.map_diag(sns.histplot)\n\n        # Add a title to the plot\n        g.fig.suptitle(f\"Pair Plot for Fall Type: {fall_type}\")\n\n        # Show the plot\n        plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Models","metadata":{}},{"cell_type":"markdown","source":"### cuda","metadata":{}},{"cell_type":"code","source":"!pip install -U numpy\nimport torch\nimport torch.cuda\nimport torch.nn.functional as F\n\n# Set the device to use\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nimport torch.nn.functional as F","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### LSTM","metadata":{}},{"cell_type":"code","source":"\nclass MHSelfAttention(nn.Module):\n    def __init__(self, embed_dim, num_heads):\n        super(MHSelfAttention, self).__init__()\n\n        # initialize MHSelfAttention\n        self.num_heads = num_heads\n        self.embed_dim = embed_dim\n        self.head_dim = embed_dim // num_heads\n        assert self.head_dim * num_heads == embed_dim, \"Embedding dimension must be divisible by number of heads\"\n\n        self.query = nn.Linear(embed_dim, embed_dim)\n        self.key = nn.Linear(embed_dim, embed_dim)\n        self.value = nn.Linear(embed_dim, embed_dim)\n        self.out = nn.Linear(embed_dim, embed_dim)\n\n    def forward(self, x):\n        batch_size = x.size(0)\n\n        # Linear projections for Query, Key and value\n        Q = self.query(x)\n        K = self.key(x)\n        V = self.value(x)\n\n        # Split into heads\n        Q = Q.view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n        K = K.view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n        V = V.view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n\n        # Scaled dot-product attention\n        scores = torch.matmul(Q, K.transpose(-2, -1)) / torch.sqrt(torch.tensor(self.head_dim, dtype=torch.float32))\n        attn = F.softmax(scores, dim=-1)\n        context = torch.matmul(attn, V)\n\n        # Concatenate heads\n        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.embed_dim)\n\n        return self.out(context)\n    \n### -------------- ###\n\n# Define the LSTM-SelfAttention model with embedding layer\nclass LSTM_SelfAttention(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, dropout, num_heads, fc_layers, embedding_dim):\n        super(LSTM_SelfAttention, self).__init__()\n        self.hidden_dim = hidden_dim\n        self.num_layers = num_layers\n        self.num_heads = num_heads\n        self.embedding_dim = embedding_dim\n        \n        # Embedding layer\n        self.embedding = nn.Embedding(input_dim, embedding_dim)\n        \n        # LSTM layer\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n        \n        # Define layers\n        self.self_attn = MHSelfAttention(embedding_dim, num_heads)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n        \n        # Fully connected layers\n        self.fc_layers = nn.ModuleList()\n        for in_size, out_size in zip(fc_layers[:-1], fc_layers[1:]):\n            self.fc_layers.append(nn.Linear(in_size, out_size))\n            self.fc_layers.append(nn.ReLU())\n\n    def forward(self, x):\n        # Pass through embedding layer\n        x = self.embedding(x)\n        \n        # Pass through LSTM layer\n        x, _ = self.lstm(x)\n        \n        # Pass through self-attention\n        x = self.self_attn(x)\n        \n        # Pass through fully connected layers\n        for layer in self.fc_layers:\n            x = layer(x)\n        \n        # Pass through final fully connected layer\n        x = self.fc(x)\n        \n        return x\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**drop columns**","metadata":{}},{"cell_type":"code","source":"df = df.drop('label', axis=1) # as we already encoded the labels with fall (boolean)\ndf = df.drop('Activity Type', axis=1) # as we already encoded the labels with fall (boolean)\ndf = df.drop('Trial No', axis=1) # as we already encoded the labels with fall (boolean)\ndf = df.drop('Sensor Type', axis=1) # as we already encoded the labels with fall (boolean)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prepare data","metadata":{}},{"cell_type":"code","source":"import torch\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Convert non-numeric columns to numeric\ndf = df.apply(pd.to_numeric, errors='coerce')\n\n# Separate features (X) and target (y)\nX = torch.from_numpy(df.drop('Fall', axis=1).values)\ny = torch.from_numpy(df['Fall'].values)\n\nprint(X)\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nX_train = torch.tensor(X_train, dtype=torch.float).to(device)\ny_train = torch.tensor(y_train, dtype=torch.float).to(device)\nX_test = torch.tensor(X_test, dtype=torch.float).to(device)\ny_test = torch.tensor(y_test, dtype=torch.float).to(device)\n\n\n# Create DataLoaders\nbatch_size = 8\ntrain_data = TensorDataset(X_train, y_train)\ntrain_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\ntest_data = TensorDataset(X_test, y_test)\ntest_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Hyperparameters","metadata":{}},{"cell_type":"code","source":"input_dim = X_train.shape[1]  # Number of input features\nhidden_dim = 32  # Number of hidden units in LSTM\noutput_dim = 1  # Number of output classes\nnum_layers = 2  # Number of LSTM layers\ndropout = 0.2  # Dropout probability\nfc_layers = [64, 32, 16, 8]  # You can adjust the number and size of fully connected layers\nlearning_rate = 0.001\nnum_heads = 4 # self_attention\nembedding_dim = 64  # You can adjust this dimension as needed\nnum_epochs = 30  # Number of training epochs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!conda install pytorch torchvision cudatoolkit=9.0 -c pytorch","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = LSTM_SelfAttention(input_dim, hidden_dim, output_dim, num_layers, dropout, num_heads, fc_layers, embedding_dim)\nmodel = model.to(device)\n\ncriterion = nn.BCEWithLogitsLoss()  # Binary Cross-Entropy Loss\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\nmodel.train()\nfor epoch in range(num_epochs):\n    total_loss = 0\n    for batch, (X_batch, y_batch) in enumerate(train_loader):\n        optimizer.zero_grad()\n        outputs = model(X_batch)\n        loss = criterion(outputs, y_batch)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    \n    avg_loss = total_loss / len(train_loader)\n    print(f\"Epoch {epoch+1}: Loss = {avg_loss:.4f}\")\n    model.eval()\n    total_accuracy = 0\n    \nwith torch.no_grad():\n    for X_batch, y_batch in test_loader:\n        y_pred = model(X_batch)\n        y_pred_binary = torch.round(torch.sigmoid(y_pred))\n        accuracy = torch.sum(y_pred_binary == y_batch).item() / len(y_batch)\n        total_accuracy += accuracy\n    avg_accuracy = total_accuracy / len(test_loader)\n    print(f\"Test Accuracy: {avg_accuracy:.4f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}